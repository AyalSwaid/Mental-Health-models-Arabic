{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "## Dataset\n",
    "We provide the model with 2 datasets: **messages** and **conversation info**.\n",
    "\n",
    "Both datasets contains more information, but We will describe only what's neccessary.\n",
    "\n",
    "**Messages** contains \n",
    "* engagement_id \n",
    "* text (original messages) \n",
    "* anonymized (modified messages by Sahar volunteers)\n",
    "\n",
    "**Conversation info** contains\n",
    "* engagement_id\n",
    "* gsr (suicide score assessment - 0 or 1)\n",
    "\n",
    "## Flow of the model\n",
    "We try to predict whether a help-seeker is suicidal based on a combination of the chat and his gsr score.\n",
    "\n",
    "This model takes into account for each chat all the messages of the help seeker, and the counselor messages.\n",
    "\n",
    "If the conversation is too long, only the last 512 tokens are taken.\n",
    "\n",
    "* We merge both datasets based on engagement_id.\n",
    "* We tokenize every batch\n",
    "* We train the model\n",
    "* OPTIONAL: We can add differential privacy to the model. It seems like the optimal threshold is around 0.009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/astrin/')\n",
    "from imports import *\n",
    "\n",
    "seed_everything()\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'onlplab/alephbert-base'\n",
    "epochs = 3\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "max_len = 512\n",
    "\n",
    "classification_threshold = 0.3\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_info_path = '/home/astrin/Projects/Sahar/Dataset/conv_info.csv'\n",
    "messages_path = '/home/astrin/Projects/Sahar/Dataset/messages_anonymized.csv'\n",
    "\n",
    "conv_info_df = pd.read_csv(conv_info_path)\n",
    "messages_df = pd.read_csv(messages_path)\n",
    "\n",
    "conv_info_df['engagement_id'] = conv_info_df['engagement_id'].astype(str)\n",
    "messages_df['engagement_id'] = messages_df['engagement_id'].astype(str)\n",
    "messages_df = messages_df[messages_df['anonymized'].notna()]\n",
    "messages_df['name'] = messages_df['name'].fillna('-')\n",
    "\n",
    "# Get all engagement_ids from conv_info_df\n",
    "ids = conv_info_df['engagement_id']\n",
    "conv_info_df = conv_info_df[conv_info_df['engagement_id'].isin(ids)]\n",
    "messages_df = messages_df[messages_df['engagement_id'].isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping messages with conversation information to pair text and label\n",
    "merged_df = messages_df.merge(conv_info_df, on='engagement_id')\n",
    "\n",
    "# Aggregating messages such that each row contains the entire conversation\n",
    "merged_df = merged_df.groupby('engagement_id').agg({'anonymized': '[SEP]'.join, 'gsr': 'first'}).reset_index()\n",
    "\n",
    "# Renaming label column (convention) and creating a Dataset object\n",
    "merged_df = merged_df.rename(columns={'gsr': 'label'})\n",
    "\n",
    "# Split to train and test stratified by label\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, stratify=merged_df['label'])\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['anonymized'], return_tensors='pt')\n",
    "    # Take last 512 tokens\n",
    "    tokens['input_ids'] = tokens['input_ids'][:, -max_len:]\n",
    "    tokens['attention_mask'] = tokens['attention_mask'][:, -max_len:]\n",
    "\n",
    "    # Now pad to 512\n",
    "    pad_len = max_len - tokens['input_ids'].shape[1]\n",
    "    tokens['input_ids'] = F.pad(tokens['input_ids'], (0, pad_len), value=tokenizer.pad_token_id)\n",
    "    tokens['attention_mask'] = F.pad(tokens['attention_mask'], (0, pad_len), value=0)\n",
    "    return tokens\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=1)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=1)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, learning_rate, device=device):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "\n",
    "    pbar = tqdm(total=epochs * len(loader), leave=False, desc='Training')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for batch in loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # DP\n",
    "            # Clipping gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Adding differential privacy noise to gradients\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad = param.grad +  torch.normal(0, 0.025, size=param.grad.shape, device=param.grad.device)\n",
    "            # End of DP\n",
    "        \n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    pbar.close()\n",
    "    return losses\n",
    "\n",
    "def test(model, loader, device=device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probs = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Testing'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_batch = batch['label'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            probs_batch = torch.softmax(logits, dim=1)\n",
    "            predictions_batch = torch.argmax(probs_batch, dim=1)\n",
    "            predictions.extend(predictions_batch.cpu().numpy())\n",
    "            probs.extend(probs_batch.cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "    return predictions, np.array(probs), labels\n",
    "\n",
    "def compute_metrics(predictions, probs, labels):\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    roc_auc = roc_auc_score(labels, probs[:, 1])\n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'roc_auc': roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(bert_model, train_loader, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, probs, labels = test(bert_model, test_loader)\n",
    "metrics = compute_metrics(preds, np.array(probs), labels)\n",
    "for key, value in metrics.items():\n",
    "    print(f'{key}: {round(value, 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
