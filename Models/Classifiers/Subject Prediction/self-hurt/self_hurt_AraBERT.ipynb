{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUBPsGhXw0Cx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, fbeta_score, accuracy_score\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers.models.bert.modeling_bert import BertOnlyMLMHead\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    BertConfig,\n",
        "    BertModel,\n",
        "    AutoConfig,\n",
        "    PreTrainedModel,\n",
        ")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_fscore_support,\n",
        "    fbeta_score,\n",
        "    accuracy_score,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "# Setup timestamped printing\n",
        "import builtins\n",
        "from datetime import datetime\n",
        "get_time = lambda: f\"[{datetime.now():%H:%M:%S}]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and prepare data"
      ],
      "metadata": {
        "id": "UDOakQe8w5P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversations_path = \"arabic_conversations.csv\"\n",
        "messages_path = \"arabic_messages.csv\"\n",
        "ARABIC_LEXICON_PATH = \"new_arabic_lexicon_17_07.csv\"\n",
        "TOTAL_LEXICON_CATEGORIES = 47\n",
        "LEXICON_ARABIC_PHRASE_COLUMN = \"Arabic Phrase (Linor Translation / Approval)\"\n",
        "\n",
        "\n",
        "test_size = 0.3\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "p3EsETDww3bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle, os\n",
        "load_dir = \"/master/saved_objects\"\n",
        "\n",
        "pkl_train_conv = pickle.load(open(os.path.join(load_dir, \"train_conv.pkl\"), 'rb'))\n",
        "pkl_test_conv = pickle.load(open(os.path.join(load_dir, \"test_conv.pkl\"), 'rb'))\n",
        "pkl_unlabeled_msgs = pickle.load(open(os.path.join(load_dir, \"unlabeled_msgs.pkl\"), 'rb'))\n",
        "pkl_train_msgs = pickle.load(open(os.path.join(load_dir, \"train_msgs.pkl\"), 'rb'))\n",
        "pkl_test_msgs = pickle.load(open(os.path.join(load_dir, \"test_msgs.pkl\"), 'rb'))\n",
        "pkl_pretrain_messages_df = pickle.load(open(os.path.join(load_dir, \"pretrain_messages_df.pkl\"), 'rb'))\n",
        "\n",
        "\n",
        "\n",
        "seeker_messages_train = pkl_train_msgs[pkl_train_msgs['seeker']]\n",
        "full_convs_train = seeker_messages_train.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))\n",
        "\n",
        "seeker_messages_test = pkl_test_msgs[pkl_test_msgs['seeker']]\n",
        "full_convs_test = seeker_messages_test.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))"
      ],
      "metadata": {
        "id": "fghiVHchw_zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_binary_label(df):\n",
        "    df['label'] = df.apply(lambda row: 1 if 'פציעה עצמית' in [row['subject_1'], row['subject_2'], row['subject_3']] else 0, axis=1)\n",
        "    return df\n",
        "\n",
        "def plot_label_distribution(df_train, df_test):\n",
        "    train_counts = df_train['label'].value_counts()\n",
        "    test_counts = df_test['label'].value_counts()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # --- Train Plot ---\n",
        "    axes[0].pie(\n",
        "        train_counts,\n",
        "        labels=[f'{label}\\n{count} ({count / train_counts.sum() * 100:.1f}%)'\n",
        "                for label, count in zip(train_counts.index, train_counts)],\n",
        "        startangle=90\n",
        "    )\n",
        "    axes[0].set_title('Train Label Distribution')\n",
        "\n",
        "    # --- Test Plot ---\n",
        "    axes[1].pie(\n",
        "        test_counts,\n",
        "        labels=[f'{label}\\n{count} ({count / test_counts.sum() * 100:.1f}%)'\n",
        "                for label, count in zip(test_counts.index, test_counts)],\n",
        "        startangle=90\n",
        "    )\n",
        "    axes[1].set_title('Test Label Distribution')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "pkl_train_conv = create_binary_label(pkl_train_conv)\n",
        "pkl_test_conv = create_binary_label(pkl_test_conv)\n",
        "\n",
        "plot_label_distribution(pkl_train_conv, pkl_test_conv)"
      ],
      "metadata": {
        "id": "LAslQa-XxNSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define some utility funcs"
      ],
      "metadata": {
        "id": "-2Ec8WzBxSG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    import random\n",
        "    import numpy as np\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "\n",
        "def classification_report_with_f2(y_true, y_pred, label_names=None, beta=2.0, digits=4):\n",
        "    # 1) Fix label set and order explicitly\n",
        "    labels = sorted(np.unique(np.concatenate([y_true, y_pred])))\n",
        "\n",
        "    # 2) Consistent zero_division across all calls\n",
        "    zd = 0\n",
        "\n",
        "    # Per-class metrics\n",
        "    p, r, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, labels=labels, average=None, zero_division=zd\n",
        "    )\n",
        "    f2 = fbeta_score(y_true, y_pred, beta=beta, labels=labels, average=None, zero_division=zd)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Build a DataFrame like classification_report + F2\n",
        "    index = [str(l) for l in labels] if label_names is None else list(label_names)\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"precision\": p,\n",
        "            \"recall\": r,\n",
        "            \"f1-score\": f1,\n",
        "            \"f2-score\": f2,\n",
        "            \"support\": support.astype(int),\n",
        "        },\n",
        "        index=index\n",
        "    )\n",
        "    # print(f2)\n",
        "    print(\"\\n\", df.round(3))\n",
        "\n",
        "    return df.round(4), f2[1]\n"
      ],
      "metadata": {
        "id": "U9GKMXo8xOgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_id = \"./pretrain/mlm & reg arabertv02 large (lr=7e-6)/bert_pretrained\"\n",
        "tokenizer_id = \"aubmindlab/bert-large-arabertv02\"\n",
        "\n",
        "conversations_path = \"arabic_conversations.csv\"\n",
        "messages_path = \"arabic_messages.csv\"\n",
        "\n",
        "seed = 42\n",
        "seed_everything(seed)\n",
        "\n",
        "num_labels = 2\n",
        "max_length = 512\n",
        "test_size = 0.3\n",
        "\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "learning_rate = 2e-5\n",
        "log_every_n = 200\n",
        "\n",
        "\n",
        "max_f2_score = 0 # best f2 score over the epochs\n",
        "best_model = None # best model over the epochs (by f2 score)\n",
        "best_model_epoch = 0 # what epoch was the best model\n",
        "last_f2_value = 0 # value of f2 at the end of training (all epochs)\n",
        "\n",
        "current_run_time = datetime.now().strftime(\"%d-%m-%Y-_%H-%M\")\n",
        "save_dir = f\"./BERT_saves/run - {current_run_time}\"\n",
        "\n",
        "all_evaluation_epochs = []  # list of eval metrics for each epoch\n",
        "\n",
        "\n",
        "class SaharDataset(Dataset):\n",
        "    def __init__(self, conversations_df, messages_df, tokenizer, max_length=max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        seeker_messages = messages_df[messages_df['seeker']]\n",
        "\n",
        "        grouped = seeker_messages.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))\n",
        "        merged = pd.merge(grouped, conversations_df[['engagement_id', 'label']], on='engagement_id')\n",
        "\n",
        "        self.labels = merged['label'].tolist()\n",
        "\n",
        "        #\n",
        "        self.encodings = tokenizer(\n",
        "            merged['text'].tolist(),\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        self.texts = merged['text'].values\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.encodings['input_ids'][idx],\n",
        "            'attention_mask': self.encodings['attention_mask'][idx],\n",
        "            'labels': self.labels[idx],\n",
        "            \"text\": self.texts[idx]\n",
        "        }\n",
        "\n",
        "\n",
        "def create_dataloaders(conversations_df, messages_df, tokenizer, batch_size=16, seed=42, test_size=0.2, max_length=max_length):\n",
        "    global pkl_train_conv\n",
        "    global pkl_test_conv\n",
        "\n",
        "    train_conv, test_conv = pkl_train_conv, pkl_test_conv\n",
        "\n",
        "    # Split messages based on engagement_id from conversations splits\n",
        "    train_ids = set(train_conv['engagement_id'].values)\n",
        "    test_ids = set(test_conv['engagement_id'].values)\n",
        "\n",
        "    train_msgs = messages_df[messages_df['engagement_id'].isin(train_ids)]\n",
        "    test_msgs = messages_df[messages_df['engagement_id'].isin(test_ids)]\n",
        "\n",
        "    # Create datasetso\n",
        "    train_dataset = SaharDataset(train_conv, train_msgs, tokenizer, max_length=max_length)\n",
        "    test_dataset = SaharDataset(test_conv, test_msgs, tokenizer, max_length=max_length)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, device, curr_epoch):\n",
        "    global max_f2_score\n",
        "    global best_model\n",
        "    global best_model_epoch\n",
        "    global last_f2_value\n",
        "    global epochs\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"Epoch: {curr_epoch}\")\n",
        "    metrics_df, f2 = classification_report_with_f2(all_labels, all_preds)\n",
        "\n",
        "    all_evaluation_epochs.append(metrics_df.iloc[1, :].to_dict())\n",
        "\n",
        "    if max_f2_score < f2: # save best version\n",
        "        max_f2_score = f2\n",
        "        best_model = model\n",
        "        best_model_epoch = curr_epoch\n",
        "\n",
        "    if curr_epoch == epochs:\n",
        "        last_f2_value = f2\n",
        "\n",
        "    return f2\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    epochs=3,\n",
        "    scheduler=None,\n",
        "    log_every_n=10\n",
        "):\n",
        "    model.to(device)\n",
        "    global current_run_time\n",
        "    global last_f2_value\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "\n",
        "            if (batch_idx + 1) % log_every_n == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
        "\n",
        "        f2 = evaluate(model, test_loader, device, curr_epoch=epoch+1)\n",
        "        model.save_pretrained(f\"{save_dir}/epoch={epoch+1}_f2={f2:.3f}__{current_run_time}\")\n",
        "\n",
        "\n",
        "    if best_model is not None:\n",
        "        best_model.save_pretrained(f\"{save_dir}/best f2={max_f2_score:.3f}_epoch={best_model_epoch}_{current_run_time}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "print(\"Loading model and tokenizer...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=num_labels)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# return\n",
        "print(\"Loading conversations and messages...\")\n",
        "\n",
        "conversations = pd.read_csv(conversations_path)\n",
        "messages = pd.read_csv(messages_path)\n",
        "\n",
        "print(\"Creating dataloaders...\")\n",
        "train_loader, test_loader = create_dataloaders(conversations, messages, tokenizer, batch_size=batch_size, seed=seed, test_size=test_size, max_length=max_length)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "num_training_steps = epochs * len(train_loader)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
        "\n",
        "print(\"Starting training...\\n\")\n",
        "model = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    epochs=epochs,\n",
        "    scheduler=scheduler,\n",
        "    log_every_n=log_every_n\n",
        ")\n",
        "\n",
        "train_finish_save_dir = f\"{save_dir}/last_epoch={epochs}_f2={last_f2_value:.3f}\"\n",
        "\n",
        "\n",
        "model.save_pretrained(train_finish_save_dir)\n",
        "tokenizer.save_pretrained(train_finish_save_dir)\n",
        "\n",
        "all_evaluation_epochs_df = pd.DataFrame(all_evaluation_epochs)\n",
        "all_evaluation_epochs_df['epoch'] = np.arange(1, len(all_evaluation_epochs_df)+1)\n",
        "all_evaluation_epochs_df[[\"epoch\", 'precision','recall','f1-score','f2-score', 'support']].to_csv(f\"{save_dir}/eval_by_epoch\", index=False)\n",
        "print(f\"Model and tokenizer saved to {save_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "7oDNVSUUxyIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}