{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import warnings\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if using multiple GPUs\n",
    "torch.backends.cudnn.deterministic = True  # Make sure to set this for reproducibility\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 2\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Define valid labels for multi-label classification\n",
    "valid_labels = [\"דיכאון ועצבות קשה\", \"פציעה עצמית\", \"טראומה מינית\", \"Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "token = \"** Insert your token here **\"  # Hugging Face token\n",
    "model_name = 'google/gemma-2-9b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    load_in_4bit=True,  # 4-bit quantization\n",
    "    device_map=\"auto\",  # Automatically map layers to available devices\n",
    "    num_labels=len(valid_labels),  # Number of labels for multi-label classification\n",
    "    use_auth_token=token\n",
    ")\n",
    "\n",
    "# LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank of low-rank matrices\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # LoRA applied to attention projections\n",
    "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "bert_model = get_peft_model(bert_model, lora_config)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model = bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data\n",
    "conv_info_path = 'conv_info.csv'\n",
    "messages_path = 'messages_anonymized.csv'\n",
    "\n",
    "conv_info_df = pd.read_csv(conv_info_path)\n",
    "messages_df = pd.read_csv(messages_path)\n",
    "\n",
    "conv_info_df['engagement_id'] = conv_info_df['engagement_id'].astype(str)\n",
    "messages_df['engagement_id'] = messages_df['engagement_id'].astype(str)\n",
    "messages_df = messages_df[messages_df['text'].notna()]\n",
    "messages_df['name'] = messages_df['name'].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-label binary representation for each conversation including \"Other\"\n",
    "def assign_multi_labels(row):\n",
    "    labels = []\n",
    "    for label in valid_labels[:-1]:  # Exclude \"Other\" at first\n",
    "        if label in [row['subject_1'], row['subject_2'], row['subject_3']]:\n",
    "            labels.append(label)\n",
    "    # If no valid labels found, append \"Other\"\n",
    "    if not labels:\n",
    "        labels.append(\"Other\")\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign multi-labels (list of labels) for each row\n",
    "conv_info_df['labels'] = conv_info_df.apply(assign_multi_labels, axis=1)\n",
    "\n",
    "# Merge messages and conversation info\n",
    "merged_df = messages_df.merge(conv_info_df, on='engagement_id')\n",
    "\n",
    "# Filter only the help seeker's messages\n",
    "merged_df = merged_df[merged_df['seeker'] == True]\n",
    "\n",
    "# Aggregate the messages so each row contains an entire conversation\n",
    "merged_df = merged_df.groupby('engagement_id').agg({'text': '[SEP]'.join, 'labels': 'first'}).reset_index()\n",
    "\n",
    "# Use MultiLabelBinarizer to convert the labels into binary vectors\n",
    "mlb = MultiLabelBinarizer(classes=valid_labels)\n",
    "merged_df['label'] = mlb.fit_transform(merged_df['labels']).tolist()\n",
    "\n",
    "# Split into train and test sets, stratified by the presence of labels\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=16)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=16)\n",
    "\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=learning_rate)\n",
    "bert_model.train()\n",
    "\n",
    "progress_bar = tqdm(range(epochs * len(train_loader)), desc=\"Training\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = torch.tensor(batch['label'], dtype=torch.float32).to(device)  # Binary labels\n",
    "\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the Model\n",
    "bert_model.eval()\n",
    "labels = []\n",
    "preds = []\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    label = torch.tensor(batch['label'], dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.sigmoid(logits)  # Use sigmoid for multi-label classification\n",
    "\n",
    "    # Apply threshold to predictions (0.5 by default for binary classification)\n",
    "    predictions = (predictions > 0.5).int()\n",
    "\n",
    "    labels.extend(label.cpu().numpy())\n",
    "    preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Convert the predictions and true labels to numpy arrays\n",
    "labels = np.array(labels)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Classification Report for Multi-label\n",
    "report_dict = classification_report(labels, preds, target_names=valid_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Export the classification report to Excel\n",
    "file_path = \"gemma_multilabel_classification_report.xlsx\"\n",
    "report_df.to_excel(file_path)\n",
    "\n",
    "# Display the DataFrame to view the classification report in a tabular format\n",
    "report_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
