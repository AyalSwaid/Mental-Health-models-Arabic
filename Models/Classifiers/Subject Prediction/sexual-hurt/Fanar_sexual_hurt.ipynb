{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962523f5-0510-4ca9-86dd-aba3775a74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_pandas\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertModel, BertTokenizerFast, Trainer, AutoTokenizer,TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification, BertTokenizer,AutoModelForCausalLM,BitsAndBytesConfig, DataCollatorForLanguageModeling, TrainerCallback\n",
    "from transformers import get_scheduler, DataCollatorWithPadding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, fbeta_score, precision_score\n",
    "\n",
    "from huggingface_hub import login\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wandb\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    fbeta_score,\n",
    "    accuracy_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score\n",
    "\n",
    "from torchmetrics.functional import f1_score, accuracy\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e98bda-931c-4f06-9124-e9362d7e2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 10\n",
    "learning_rate = 7e-6\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd9c0e-1b1f-4557-bdf0-96a4b62165d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805830bb-22b7-4089-ba87-e91deb350b95",
   "metadata": {},
   "source": [
    "# Load QLoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce0237-95a6-4172-9931-b9874f629994",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\",device)\n",
    "\n",
    "token = \"your hugging face token here\"\n",
    "\n",
    "cap = torch.cuda.get_device_capability()\n",
    "use_bf16 = cap[0] >= 8  # Ampere+ usually ok\n",
    "dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "\n",
    "model_name = \"QCRI/Fanar-1-9B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "print(\"loading tokenizer\")\n",
    "tok = AutoTokenizer.from_pretrained(\"QCRI/Fanar-1-9B-Instruct\", token=token)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "tok.padding_side = \"right\"\n",
    "tok.truncation_side = \"right\"\n",
    "\n",
    "print(\"loading model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    token=token,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=dtype,\n",
    "    attn_implementation=\"eager\",   # avoid CUDA kernel asserts\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "# define classification head to replace LM head\n",
    "class ReducedLinear(nn.Module):\n",
    "    def __init__(self, in_features, original_weight=None):\n",
    "        # original_weight is the lm head weights matrix\n",
    "        super().__init__()\n",
    "        # Extract only the 2 rows of interest\n",
    "        self.weight = nn.Parameter(original_weight[[125596, 125594], :])  # [125596, 125594] are token ids of '0' and '1', which matches it with the prompt Shape: [2, 2560]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weight.t())  # Output shape: [batch_size, 2]\n",
    "\n",
    "model.lm_head = ReducedLinear(model.lm_head.in_features, model.lm_head.weight)\n",
    "\n",
    "\n",
    "# model\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
    "\n",
    "print(\"adding QLoRA adapters\")\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,  \n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
    "    modules_to_save=[\"lm_head\"],   \n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860c343-301d-411d-87de-48c256fdc31d",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edef55e-69fd-4ba4-a696-125bb3dc8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_path = \"arabic_conversations.csv\"\n",
    "messages_path = \"arabic_messages.csv\"\n",
    "ARABIC_LEXICON_PATH = \"new_arabic_lexicon_17_07.csv\"\n",
    "TOTAL_LEXICON_CATEGORIES = 47\n",
    "LEXICON_ARABIC_PHRASE_COLUMN = \"Arabic Phrase (Linor Translation / Approval)\"\n",
    "\n",
    "# MODEL_NAME = 'UBC-NLP/MARBERTv2'\n",
    "\n",
    "test_size = 0.3\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f024c-30cf-4e0f-9f3d-8744f9df0493",
   "metadata": {},
   "source": [
    "## Load saved datasets splits from pickles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47a45a-e547-4772-a6ff-2fc9496da23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "load_dir = \"/home/swaida/master/saved_objects\"\n",
    "\n",
    "pkl_train_conv = pickle.load(open(os.path.join(load_dir, \"train_conv.pkl\"), 'rb'))\n",
    "pkl_test_conv = pickle.load(open(os.path.join(load_dir, \"test_conv.pkl\"), 'rb'))\n",
    "pkl_unlabeled_msgs = pickle.load(open(os.path.join(load_dir, \"unlabeled_msgs.pkl\"), 'rb'))\n",
    "pkl_train_msgs = pickle.load(open(os.path.join(load_dir, \"train_msgs.pkl\"), 'rb'))\n",
    "pkl_test_msgs = pickle.load(open(os.path.join(load_dir, \"test_msgs.pkl\"), 'rb'))\n",
    "pkl_pretrain_messages_df = pickle.load(open(os.path.join(load_dir, \"pretrain_messages_df.pkl\"), 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "seeker_messages_train = pkl_train_msgs[pkl_train_msgs['seeker']]\n",
    "full_convs_train = seeker_messages_train.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))\n",
    "\n",
    "seeker_messages_test = pkl_test_msgs[pkl_test_msgs['seeker']]\n",
    "full_convs_test = seeker_messages_test.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5dc722-0fee-4801-a6ad-5f256cb8aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(pkl_train_msgs.engagement_id) | set(pkl_train_conv.engagement_id)) == len(pkl_train_conv)\n",
    "\n",
    "# pkl_train_conv.shape\n",
    "all_subjects = pd.concat([pkl_train_conv.subject_1, pkl_train_conv.subject_2, pkl_train_conv.subject_3]).dropna()\n",
    "all_subjects.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c59a48-65cc-4e48-bee0-7210b3cf1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_label(df):\n",
    "    df['label'] = df.apply(lambda row: 1 if 'טראומה מינית' in [row['subject_1'], row['subject_2'], row['subject_3']] else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def plot_label_distribution(df_train, df_test):\n",
    "    train_counts = df_train['label'].value_counts()\n",
    "    test_counts = df_test['label'].value_counts()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # --- Train Plot ---\n",
    "    axes[0].pie(\n",
    "        train_counts,\n",
    "        labels=[f'{label}\\n{count} ({count / train_counts.sum() * 100:.1f}%)' \n",
    "                for label, count in zip(train_counts.index, train_counts)],\n",
    "        startangle=90\n",
    "    )\n",
    "    axes[0].set_title('Train Label Distribution')\n",
    "    \n",
    "    # --- Test Plot ---\n",
    "    axes[1].pie(\n",
    "        test_counts,\n",
    "        labels=[f'{label}\\n{count} ({count / test_counts.sum() * 100:.1f}%)' \n",
    "                for label, count in zip(test_counts.index, test_counts)],\n",
    "        startangle=90\n",
    "    )\n",
    "    axes[1].set_title('Test Label Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "pkl_train_conv = create_binary_label(pkl_train_conv)\n",
    "pkl_test_conv = create_binary_label(pkl_test_conv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "concated = pd.concat([pkl_train_conv,pkl_test_conv])\n",
    "pkl_train_conv, pkl_test_conv = train_test_split(concated, test_size=0.3, stratify=concated['label'], random_state=42)\n",
    "\n",
    "all_msgs = pd.concat([pkl_train_msgs, pkl_test_msgs]) \n",
    "\n",
    "pkl_train_msgs = all_msgs[all_msgs['engagement_id'].isin(pkl_train_conv['engagement_id'].unique())]\n",
    "pkl_test_msgs = all_msgs[all_msgs['engagement_id'].isin(pkl_test_conv['engagement_id'].unique())]\n",
    "\n",
    "\n",
    "seeker_messages_train = pkl_train_msgs[pkl_train_msgs['seeker']]\n",
    "full_convs_train = seeker_messages_train.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))\n",
    "\n",
    "seeker_messages_test = pkl_test_msgs[pkl_test_msgs['seeker']]\n",
    "full_convs_test = seeker_messages_test.groupby('engagement_id')['text'].apply(lambda texts: '. '.join(texts))\n",
    "\n",
    "\n",
    "plot_label_distribution(pkl_train_conv, pkl_test_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734c23e-a311-4fea-95d0-32b8069a5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def insert_prompt(conv_text, without_answer=True):\n",
    "    prompt = \"النص التالي هو محادثة لشخص مع طبيب نفسي, هل يقول الشخص انه يتعرض لمضايقة جنسية او تحرش جنسي؟ اجب فقط 1(نعم) او 0(لا) باللغة العربية\"\n",
    "    mention_domain_knowledge = \"الجمل التالية هي مؤشرات لرغبة بالانتحار او ايذاء النفس:\"\n",
    "    yes = \"نعم\"\n",
    "    no = \"لا\"\n",
    "    the_text = \"المجادثة:\"\n",
    "    answer = \"الاجابة:\"\n",
    "    \n",
    "\n",
    "    if without_answer:\n",
    "        return f\"\"\"{prompt}\n",
    "            \n",
    "            \n",
    "            {the_text} {conv_text}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"{prompt}\n",
    "        {mention_domain_knowledge}\n",
    "        {SUICIDE_PHRASES}\n",
    "    \n",
    "        \n",
    "        {the_text} {conv_text}\n",
    "        \n",
    "        {answer} \"\"\"\n",
    "\n",
    "    \n",
    "def change_dataset_content_structure():\n",
    "    train_df = pd.merge(pkl_train_conv, full_convs_train.reset_index(), on=\"engagement_id\", how=\"inner\")[['engagement_id', 'label','text']]\n",
    "    test_df = pd.merge(pkl_test_conv, full_convs_test.reset_index(), on=\"engagement_id\", how=\"inner\")[['engagement_id', 'label','text']]\n",
    "    \n",
    "    assert len(train_df) == len(full_convs_train)\n",
    "    assert len(test_df) == len(full_convs_test)\n",
    "\n",
    "    train_df.loc[:, 'text_prompt_and_conv'] = train_df['text'].apply(insert_prompt)\n",
    "    test_df.loc[:, 'text_prompt_and_conv'] = test_df['text'].apply(insert_prompt)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def tokenize(batch, dont_truncate_answer=True):\n",
    "    # print(batch)\n",
    "    if dont_truncate_answer:\n",
    "        ANSWER = \"الاجابة:\"\n",
    "        prompt_answer_postfix = f\"\"\"\n",
    "        \n",
    "        {ANSWER} \"\"\"\n",
    "        enc = tok(batch['text_prompt_and_conv'], padding=False, truncation=True, max_length=700)\n",
    "        enc_prompt_answer_postfix = tok(prompt_answer_postfix, add_special_tokens=False, padding=False, truncation=True, max_length=1000)\n",
    "\n",
    "        enc[\"labels\"] = batch[\"label\"]\n",
    "        for enc_key in ['input_ids', 'attention_mask']:\n",
    "            assert isinstance(enc[enc_key], list) and isinstance(enc_prompt_answer_postfix[enc_key], list) # the next \"+\" operation assumes they are lists\n",
    "            enc[enc_key] = enc[enc_key] + enc_prompt_answer_postfix[enc_key]\n",
    "\n",
    "        return enc\n",
    "\n",
    "    else:\n",
    "        enc = tok(batch['text'], padding=False, truncation=True, max_length=1000)\n",
    "        enc[\"labels\"] = batch[\"label\"]\n",
    "        return enc\n",
    "\n",
    "def tensors_cllate_fn(batch):\n",
    "    to_t = lambda x: torch.tensor(x, dtype=torch.long)\n",
    "    input_ids = pad_sequence([to_t(b[\"input_ids\"]) for b in batch], batch_first=True, padding_value=tok.pad_token_id)\n",
    "    attention = pad_sequence([to_t(b[\"attention_mask\"]) for b in batch], batch_first=True, padding_value=0)\n",
    "    labels    = torch.cat([to_t(b[\"labels\"]).unsqueeze(0) for b in batch])\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention,\n",
    "        \"labels\": labels,                 # HF CausalLM will compute CE on non -100\n",
    "    }\n",
    "\n",
    "train_df, test_df = change_dataset_content_structure() # this also calls insert_prompt\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).map(tokenize, remove_columns=train_df.columns.to_list())\n",
    "test_dataset = Dataset.from_pandas(test_df).map(tokenize, remove_columns=train_df.columns.to_list())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=tensors_cllate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=tensors_cllate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbad16e-042d-492c-a91a-96be2e4dfcb8",
   "metadata": {},
   "source": [
    "# Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd19c4f-6bda-41fb-ba9c-76675fe23fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FanarClassifier(pl.LightningModule):\n",
    "    def __init__(self, hf_model, learning_rate=7e-6):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['hf_model'])\n",
    "        \n",
    "        self.model = hf_model  # returns logits of shape [B, 2]\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight = torch.tensor([0.0001, 0.9], device=\"cuda\")  # example weights\n",
    ")\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.val_all_preds = []\n",
    "        self.val_all_labels = []\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids=batch[\"input_ids\"]\n",
    "        attention_mask=batch[\"attention_mask\"]\n",
    "        labels=batch[\"labels\"]\n",
    "        output_obj = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = output_obj.logits[:, -1, :]  # take only the logits of the last token in the last linear layer. [B, 2]\n",
    "        loss = None\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels.long())\n",
    "        else:\n",
    "            raise Exception(\"error: why are labels==None ??!!\")\n",
    "\n",
    "        preds = (logits.argmax(dim=1)).long() # shape [B]\n",
    "\n",
    "        \n",
    "        assert (loss is not None) \n",
    "        return {\"logits\": logits, \"loss\": loss, \"preds\": preds}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(batch)\n",
    "        \n",
    "        preds = out[\"preds\"]\n",
    "        \n",
    "        self.log(\"train_loss\", out[\"loss\"], on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return out[\"loss\"]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(batch)\n",
    "\n",
    "        \n",
    "        preds = out[\"preds\"]\n",
    "\n",
    "        self.val_all_preds.append(preds)\n",
    "        self.val_all_labels.append(batch[\"labels\"])\n",
    "        \n",
    "        self.log(\"val_loss\", out[\"loss\"], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return out[\"loss\"]\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds, all_labels = torch.cat(self.val_all_preds), torch.cat(self.val_all_labels)\n",
    "        print(f\"eppcj preds shape: {all_preds.shape}, epoch labels shape: {all_labels.shape}\")\n",
    "        \n",
    "        epoch_acc = accuracy(task=\"binary\", preds=all_preds, target=all_labels)\n",
    "        precision = precision_score(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n",
    "        recall = recall_score(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n",
    "        epoch_f1 = f1_score(task=\"binary\", preds=all_preds, target=all_labels)\n",
    "        epoch_f2 = fbeta_score(all_labels.cpu().numpy(), all_preds.cpu().numpy(), beta=2, labels=[0,1], average=None, zero_division=0)[1]\n",
    "        \n",
    "        self.log(\"epoch_val_acc\", epoch_acc, prog_bar=True)\n",
    "        self.log(\"epoch_val_precision\", precision, prog_bar=True)\n",
    "        self.log(\"epoch_val_recall\", recall, prog_bar=True)\n",
    "        self.log(\"epoch_val_f1\", epoch_f1, prog_bar=True)\n",
    "        self.log(\"epoch_val_f2\", epoch_f2, prog_bar=True)\n",
    "\n",
    "        with open(\"model_preds_DK.txt\", \"w+\") as f:\n",
    "            f.write(str(self.val_all_preds))\n",
    "\n",
    "        with open(\"true_labels_DK.txt\", \"w+\") as f:\n",
    "            f.write(str(self.val_all_labels))\n",
    "            \n",
    "        self.val_all_preds.clear()\n",
    "        self.val_all_labels.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=3,\n",
    "            num_training_steps=len(train_loader)*epochs  # replace with actual total steps\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f69949-062b-47c1-bf43-ecc7efe6b3a6",
   "metadata": {},
   "source": [
    "# Train\n",
    "**Evaluation logs on wandb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756ad8f-ea35-4c9f-bc17-89a33cc75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FanarClassifier(model, learning_rate=2e-5)\n",
    "\n",
    "exp_name = \"Fanar (lr=2e-5) seq_len=700\"\n",
    "wandb_logger = WandbLogger(project=\"sexual-hurt-pred\", name=exp_name,\n",
    "                               group=\"decoder\", resume=True)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=6,\n",
    "    accumulate_grad_batches=8,\n",
    "    log_every_n_steps=20,\n",
    "    val_check_interval=0.25,  # validate 4x/epoch; adjust as desired\n",
    "    precision=\"16-mixed\",\n",
    "    logger=wandb_logger\n",
    ")\n",
    "\n",
    "trainer.fit(my_model, train_loader, test_loader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env”\n\n\nsjupyter\n\n\n\n\n\n\n\nexit\n\n\n[200~ ~dasd\n\nreset\n\nexit()\n\n",
   "language": "python",
   "name": "master_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
